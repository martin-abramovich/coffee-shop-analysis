version: "3.8"

services:
  # ==================== MIDDLEWARE ====================
  rabbitmq:
    image: rabbitmq:3-management
    container_name: coffee-rabbitmq
    ports:
      - "5672:5672"
      - "15672:15672"
    environment:
      RABBITMQ_DEFAULT_USER: guest
      RABBITMQ_DEFAULT_PASS: guest
      RABBITMQ_LOG_LEVEL: warning
      RABBITMQ_HEARTBEAT: 300  # 5 minutes instead of default 60s
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "check_port_connectivity"]
      interval: 5s
      timeout: 10s
      retries: 10
      start_period: 30s
    networks:
      - coffee-network

  # ==================== GATEWAY ====================
  gateway:
    build:
      context: .
      dockerfile: Dockerfile.gateway
    container_name: coffee-gateway
    labels:
      - "role=node"
    ports:
      - "9000:9000"
      - "8888:8888/udp"  # Puerto UDP para healthcheck
    environment:
      RABBITMQ_HOST: ${RABBITMQ_HOST}
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}
      HEALTHCHECK_PORT: ${HEALTHCHECK_PORT:-8888}
    depends_on:
      rabbitmq:
        condition: service_healthy
    networks:
      - coffee-network
    volumes:
      - ./results:/app/results

  # ==================== FILTERS ====================
  # Filter Year Workers - Agregar/quitar workers según necesidad
  # IMPORTANTE: NUM_FILTER_YEAR_WORKERS en .env debe coincidir con la cantidad de workers aquí
  filter_year_0:
    build:
      context: .
      dockerfile: Dockerfile.worker
    container_name: coffee-filter-year-0
    labels:
      - "role=node"
    command: ["python", "-m", "workers.filter.filter_year"]
    environment:
      RABBITMQ_HOST: ${RABBITMQ_HOST}
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}
      HEALTHCHECK_PORT: ${HEALTHCHECK_PORT:-8888}
      WORKER_ID: 0
    depends_on:
      rabbitmq:
        condition: service_healthy
    networks:
      - coffee-network

  filter_year_1:
    build:
      context: .
      dockerfile: Dockerfile.worker
    container_name: coffee-filter-year-1
    labels:
      - "role=node"
    command: ["python", "-m", "workers.filter.filter_year"]
    environment:
      RABBITMQ_HOST: ${RABBITMQ_HOST}
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}
      WORKER_ID: 1
    depends_on:
      rabbitmq:
        condition: service_healthy
    networks:
      - coffee-network

  filter_year_2:
    build:
      context: .
      dockerfile: Dockerfile.worker
    container_name: coffee-filter-year-2
    labels:
      - "role=node"
    command: ["python", "-m", "workers.filter.filter_year"]
    environment:
      RABBITMQ_HOST: ${RABBITMQ_HOST}
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}
      HEALTHCHECK_PORT: ${HEALTHCHECK_PORT:-8888}
      NUM_FILTER_HOUR_WORKERS: ${NUM_FILTER_HOUR_WORKERS}
      WORKER_ID: 2
    depends_on:
      rabbitmq:
        condition: service_healthy
    networks:
      - coffee-network

  # Para agregar más workers:
  # 1. Copia uno de los bloques anteriores
  # 2. Cambia el nombre a filter_year_3, filter_year_4, etc.
  # 3. Cambia WORKER_ID: 3, 4, etc.
  # 4. Actualiza NUM_FILTER_YEAR_WORKERS en .env

  # Filter Hour Workers - Agregar/quitar workers según necesidad
  filter_hour_0:
    build:
      context: .
      dockerfile: Dockerfile.worker
    container_name: coffee-filter-hour-0
    labels:
      - "role=node"
    command: ["python", "-m", "workers.filter.filter_hour"]
    environment:
      RABBITMQ_HOST: ${RABBITMQ_HOST}
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}
      HEALTHCHECK_PORT: ${HEALTHCHECK_PORT:-8888}
      WORKER_ID: 0
    depends_on:
      rabbitmq:
        condition: service_healthy
    networks:
      - coffee-network

  filter_hour_1:
    build:
      context: .
      dockerfile: Dockerfile.worker
    container_name: coffee-filter-hour-1
    labels:
      - "role=node"
    command: ["python", "-m", "workers.filter.filter_hour"]
    environment:
      RABBITMQ_HOST: ${RABBITMQ_HOST}
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}
      HEALTHCHECK_PORT: ${HEALTHCHECK_PORT:-8888}
      NUM_FILTER_YEAR_WORKERS: ${NUM_FILTER_YEAR_WORKERS}
      WORKER_ID: 1
    depends_on:
      rabbitmq:
        condition: service_healthy
    networks:
      - coffee-network

  # Filter Amount Workers
  filter_amount_0:
    build:
      context: .
      dockerfile: Dockerfile.worker
    container_name: coffee-filter-amount-0
    labels:
      - "role=node"
    command: ["python", "-m", "workers.filter.filter_amount"]
    environment:
      RABBITMQ_HOST: ${RABBITMQ_HOST}
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}
      HEALTHCHECK_PORT: ${HEALTHCHECK_PORT:-8888}
      WORKER_ID: 0
    depends_on:
      rabbitmq:
        condition: service_healthy
    networks:
      - coffee-network

  filter_amount_1:
    build:
      context: .
      dockerfile: Dockerfile.worker
    container_name: coffee-filter-amount-1
    labels:
      - "role=node"
    command: ["python", "-m", "workers.filter.filter_amount"]
    environment:
      RABBITMQ_HOST: ${RABBITMQ_HOST}
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}
      HEALTHCHECK_PORT: ${HEALTHCHECK_PORT:-8888}
      NUM_FILTER_HOUR_WORKERS: ${NUM_FILTER_HOUR_WORKERS}
      WORKER_ID: 1
    depends_on:
      rabbitmq:
        condition: service_healthy
    networks:
      - coffee-network

  # ==================== GROUP BY ====================
  # Group By Query2 Workers
  group_by_query2_0:
    build:
      context: .
      dockerfile: Dockerfile.worker
    container_name: coffee-group-by-query2-0
    labels:
      - "role=node"
    command: ["python", "-m", "workers.group_by.group_by_query2"]
    environment:
      RABBITMQ_HOST: ${RABBITMQ_HOST}
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}
      HEALTHCHECK_PORT: ${HEALTHCHECK_PORT:-8888}
      NUM_FILTER_YEAR_WORKERS: ${NUM_FILTER_YEAR_WORKERS}
      WORKER_ID: 0
    depends_on:
      rabbitmq:
        condition: service_healthy
    networks:
      - coffee-network

  group_by_query2_1:
    build:
      context: .
      dockerfile: Dockerfile.worker
    container_name: coffee-group-by-query2-1
    labels:
      - "role=node"
    command: ["python", "-m", "workers.group_by.group_by_query2"]
    environment:
      RABBITMQ_HOST: ${RABBITMQ_HOST}
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}
      HEALTHCHECK_PORT: ${HEALTHCHECK_PORT:-8888}
      NUM_FILTER_YEAR_WORKERS: ${NUM_FILTER_YEAR_WORKERS}
      WORKER_ID: 1
    depends_on:
      rabbitmq:
        condition: service_healthy
    networks:
      - coffee-network

  # # Group By Query3 Workers
  group_by_query3_0:
    build:
      context: .
      dockerfile: Dockerfile.worker
    container_name: coffee-group-by-query3-0
    labels:
      - "role=node"
    command: ["python", "-m", "workers.group_by.group_by_query3"]
    environment:
      RABBITMQ_HOST: ${RABBITMQ_HOST}
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}
      HEALTHCHECK_PORT: ${HEALTHCHECK_PORT:-8888}
      WORKER_ID: 0
    depends_on:
      rabbitmq:
        condition: service_healthy
    networks:
      - coffee-network

  group_by_query3_1:
    build:
      context: .
      dockerfile: Dockerfile.worker
    container_name: coffee-group-by-query3-1
    labels:
      - "role=node"
    command: ["python", "-m", "workers.group_by.group_by_query3"]
    environment:
      RABBITMQ_HOST: ${RABBITMQ_HOST}
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}
      HEALTHCHECK_PORT: ${HEALTHCHECK_PORT:-8888}
      NUM_FILTER_HOUR_WORKERS: ${NUM_FILTER_HOUR_WORKERS}
      WORKER_ID: 1
    depends_on:
      rabbitmq:
        condition: service_healthy
    networks:
      - coffee-network

  # # Group By Query4 Workers
  group_by_query4_0:
    build:
      context: .
      dockerfile: Dockerfile.worker
    container_name: coffee-group-by-query4-0
    labels:
      - "role=node"
    command: ["python", "-m", "workers.group_by.group_by_query4"]
    environment:
      RABBITMQ_HOST: ${RABBITMQ_HOST}
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}
      HEALTHCHECK_PORT: ${HEALTHCHECK_PORT:-8888}
      WORKER_ID: 0
    depends_on:
      rabbitmq:
        condition: service_healthy
    networks:
      - coffee-network

  group_by_query4_1:
    build:
      context: .
      dockerfile: Dockerfile.worker
    container_name: coffee-group-by-query4-1
    labels:
      - "role=node"
    command: ["python", "-m", "workers.group_by.group_by_query4"]
    environment:
      RABBITMQ_HOST: ${RABBITMQ_HOST}
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}
      HEALTHCHECK_PORT: ${HEALTHCHECK_PORT:-8888}
      NUM_FILTER_YEAR_WORKERS: ${NUM_FILTER_YEAR_WORKERS}
      WORKER_ID: 1
    depends_on:
      rabbitmq:
        condition: service_healthy
    networks:
      - coffee-network

  # ==================== AGGREGATORS ====================
  aggregator_query1:
    build:
      context: .
      dockerfile: Dockerfile.worker
    container_name: coffee-aggregator-query1
    labels:
      - "role=node"
    command: ["python", "-m", "workers.aggregator.aggregator_query1"]
    environment:
      RABBITMQ_HOST: ${RABBITMQ_HOST}
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}
      HEALTHCHECK_PORT: ${HEALTHCHECK_PORT:-8888}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    depends_on:
      rabbitmq:
        condition: service_healthy
    networks:
      - coffee-network
    volumes:
    - ./state/agregator1:/app/state

  aggregator_query2:
    build:
      context: .
      dockerfile: Dockerfile.worker
    container_name: coffee-aggregator-query2
    labels:
      - "role=node"
    command: ["python", "-m", "workers.aggregator.aggregator_query2"]
    environment:
      RABBITMQ_HOST: ${RABBITMQ_HOST}
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}
      HEALTHCHECK_PORT: ${HEALTHCHECK_PORT:-8888}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    depends_on:
      rabbitmq:
        condition: service_healthy
    networks:
      - coffee-network

  aggregator_query3:
    build:
     context: .
     dockerfile: Dockerfile.worker
    container_name: coffee-aggregator-query3
    labels:
      - "role=node"
    command: ["python", "-m", "workers.aggregator.aggregator_query3"]
    environment:
      RABBITMQ_HOST: ${RABBITMQ_HOST}
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}
      HEALTHCHECK_PORT: ${HEALTHCHECK_PORT:-8888}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    depends_on:
      rabbitmq:
        condition: service_healthy
    networks:
      - coffee-network
    volumes:
    - ./state/agregator3:/app/state

  aggregator_query4:
    build:
     context: .
     dockerfile: Dockerfile.worker
    container_name: coffee-aggregator-query4
    labels:
      - "role=node"
    command: ["python", "-m", "workers.aggregator.aggregator_query4"]
    environment:
      RABBITMQ_HOST: ${RABBITMQ_HOST}
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}
      HEALTHCHECK_PORT: ${HEALTHCHECK_PORT:-8888}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    depends_on:
      rabbitmq:
        condition: service_healthy
    networks:
      - coffee-network

  # ==================== MONITORS (Redundantes) ====================
  # 3 réplicas de monitores con algoritmo Bully para elección de líder
  monitor_1:
    build:
      context: .
      dockerfile: Dockerfile.monitor
    container_name: coffee-monitor-1
    environment:
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}
      MONITOR_ID: 1
      MONITOR_TCP_PORT: 9999
      HEALTHCHECK_PORT: ${HEALTHCHECK_PORT:-8888}
      CHECK_INTERVAL: ${CHECK_INTERVAL:-5.0}
      TIMEOUT: ${TIMEOUT:-2.0}
      MAX_FAILED_ATTEMPTS: ${MAX_FAILED_ATTEMPTS:-3}
      HEARTBEAT_INTERVAL: ${HEARTBEAT_INTERVAL:-3.0}
      LEADER_TIMEOUT: ${LEADER_TIMEOUT:-10.0}
      # MONITORS: "1:monitor_1:9999,2:monitor_2:10000,3:monitor_3:10001"
    depends_on:
      - gateway
    networks:
      - coffee-network
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock  # Socket Docker para revivir contenedores
    restart: unless-stopped

  monitor_2:
    build:
      context: .
      dockerfile: Dockerfile.monitor
    container_name: coffee-monitor-2
    environment:
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}
      MONITOR_ID: 2
      MONITOR_TCP_PORT: 10000
      HEALTHCHECK_PORT: ${HEALTHCHECK_PORT:-8888}
      CHECK_INTERVAL: ${CHECK_INTERVAL:-5.0}
      TIMEOUT: ${TIMEOUT:-2.0}
      MAX_FAILED_ATTEMPTS: ${MAX_FAILED_ATTEMPTS:-3}
      HEARTBEAT_INTERVAL: ${HEARTBEAT_INTERVAL:-3.0}
      LEADER_TIMEOUT: ${LEADER_TIMEOUT:-10.0}
    depends_on:
      - gateway
    networks:
      - coffee-network
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock  # Socket Docker para revivir contenedores
    restart: unless-stopped

  monitor_3:
    build:
      context: .
      dockerfile: Dockerfile.monitor
    container_name: coffee-monitor-3
    environment:
      PYTHONUNBUFFERED: ${PYTHONUNBUFFERED}
      MONITOR_ID: 3
      MONITOR_TCP_PORT: 10001
      HEALTHCHECK_PORT: ${HEALTHCHECK_PORT:-8888}
      CHECK_INTERVAL: ${CHECK_INTERVAL:-5.0}
      TIMEOUT: ${TIMEOUT:-2.0}
      MAX_FAILED_ATTEMPTS: ${MAX_FAILED_ATTEMPTS:-3}
      HEARTBEAT_INTERVAL: ${HEARTBEAT_INTERVAL:-3.0}
      LEADER_TIMEOUT: ${LEADER_TIMEOUT:-10.0}
    depends_on:
      - gateway
    networks:
      - coffee-network
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock  # Socket Docker para revivir contenedores
    restart: unless-stopped

  # ==================== CLIENT ====================
  # El cliente se ejecuta manualmente cuando sea necesario
  client:
    build:
      context: .
      dockerfile: Dockerfile.client
    environment:
      GATEWAY_HOST: gateway
      CLIENT_RESULTS_DIR: /app/results
    depends_on:
      - gateway
    networks:
      - coffee-network
    volumes:
      - ./.data:/app/.data:ro # Montar datos como solo lectura
      - ./results:/app/results
    profiles:
      - manual # No se inicia automáticamente
    # Ejemplo de uso:
    # docker-compose run --rm client --data-folder dataset1
    # docker-compose run --rm client --data-folder dataset2 --verbose

networks:
  coffee-network:
    driver: bridge

volumes:
  results:
